{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ðŸ“– Jupyter Notebook Tool ðŸ”§\n",
    "\n",
    "This tool will iterate through a notebook or several notebooks and will check them for:\n",
    " - Deny-list keywords\n",
    " - Hard-coded variables\n",
    " \n",
    "The Notebook being checked will then be given a \"grade\" depending on the severity of the issues the tool has detected. If a Notebook passes a certain grade threshold, that Notebook will then be flagged so it can be checked by a central administrator.\n",
    "\n",
    "## ðŸ’¥Table of ContentsðŸ’¥\n",
    "1. [Importing Libraries and Functions](#importfunctions) - Boring part. Loads in all the necessary functions and libraries.\n",
    "\n",
    "2. [Papermill Injection](#papermill) - Parameters for the notebooks to be checked against are injected here.\n",
    "\n",
    "3. [Load Notebooks](#loadnotebooks) - Function that loads all of notebooks ready for analysis.\n",
    "\n",
    "4. [Notebook Analysis Function](#notebookfunction) - The guts and inner-workings of the tool.\n",
    "\n",
    "6. [Detailed Report](#detailedreport) - A more in-depth line-by-line analysis of problems in the notebooks.\n",
    "\n",
    "5. [Short Report](#shortreport) - If you just want to see the results quickly.\n",
    "\n",
    "7. [Visual Report](#visualreport) - Graphical analysis easily see the worst offenders.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries and Functions <a id=\"importfunctions\"></a>\n",
    "The following code will import all of the libraries and functions we require for our tool to run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import required libraries:\n",
    "\n",
    "# *** Should we import these inside functions mixed eview on practices as it is dire to program but if functiond pulled out ad implemented in other code will require this \n",
    "import pandas as pd\n",
    "import csv\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import os\n",
    "import json\n",
    "import codecs\n",
    "import ast\n",
    "from io import StringIO\n",
    "from os import path\n",
    "#import word and regex functions for checking \n",
    "from disallowTermCheck import checkTerms\n",
    "from disallowRegexCheck import checkRegex\n",
    "# from unit_testing_nonallowedwords import checkword"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Papermill Parameter Injection <a id=\"papermill\"></a>\n",
    "Here we will define the variables that need to be injected as parameters through Papermill. This can be done by using the bash script present in the directory or by manually typing the command in a CLI for more control.\n",
    "\n",
    "Now is the time to check your RegEx and check that it is correct, and more importantly does not contain commas. If your RegEx contains commas, then the notebookChecker function will not work. If the tool is not correctly detecting RegEx, then it is recommended to use a more specific and in-depth RegEx pattern."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "#parameters for disallowed list and url \n",
    "notebookList ='This parameter will be passed through papermill'\n",
    "disallowedTermsList = 'This parameter will be passed through papermill'\n",
    "disallowedRegexList = 'This parameter will be passed through papermill'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load in Notebooks <a id=\"loadnotebooks\"></a>\n",
    "Here we load in the Jupyter Notebooks from the current working directory (can be defined) and read them in. Jupyter Notebooks are in JSON format, meaning that to accurately read in the lines of text as they are seen in the cells we have to use the appropriate keys.\n",
    "\n",
    "In this case, the whole contents of the notebooks is encompassed in ['cells'] and every cell has a ['source'] which contains the contents of the cells.\n",
    "\n",
    "The contents of ['source'] is then added to the empty list called currentNotebook line by line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readNotebook(notebookToReadPath):\n",
    "    try:\n",
    "                file = codecs.open(notebookToReadPath, \"r\")\n",
    "                source = file.read()\n",
    "                y = json.loads(source)\n",
    "                currentNotebook = []\n",
    "                for x in y['cells']:\n",
    "                    for x2 in x['source']:\n",
    "                        currentNotebook.append(x2)\n",
    "                \n",
    "                return currentNotebook\n",
    "    except:\n",
    "        print(\"Can't read file\")\n",
    "        return False"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notebook Checker Function <a id=\"notebookfunction\"></a>\n",
    "\n",
    "The following function will take the papermill parameters and the list of notebooks and start notebook analysis. It does this by using the two analysis functions: disallowTermChecker.py and disallowRegexChecker.py\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 1 is out of bounds for axis 0 with size 1",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_58500\\3649105990.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     94\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     95\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 96\u001b[1;33m \u001b[0mnotebookResults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnotebookChecker\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdisallowedTermsList\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdisallowedRegexList\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnotebookList\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     97\u001b[0m \u001b[1;31m# print(notebookResults)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_58500\\3649105990.py\u001b[0m in \u001b[0;36mnotebookChecker\u001b[1;34m(disallowedTermsList, disallowedRegexList, notebookList)\u001b[0m\n\u001b[0;32m     14\u001b[0m     \u001b[0moverallTermCount\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mitem\u001b[0m \u001b[1;32min\u001b[0m \u001b[0msortedList\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m         \u001b[0mtermIndexKey\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m         \u001b[0mtermWeightKey\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m         \u001b[0mdisallowedList\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: index 1 is out of bounds for axis 0 with size 1"
     ]
    }
   ],
   "source": [
    "#notebook checker function \n",
    "def notebookChecker(disallowedTermsList,disallowedRegexList, notebookList):\n",
    "    directory = path.dirname(__file__) if \"__file__\" in locals() else os.getcwd()\n",
    "\n",
    "    '''This takes the CSV string injected via papermill and puts it into a sorted list for both the deny list words\n",
    "    #and the RegEx list.\n",
    "    # The lists are then sorted and placed into disallowed lists.''' \n",
    "\n",
    "    csvTermsStringIO = StringIO(disallowedTermsList)\n",
    "    sortedList = np.array(pd.read_csv(csvTermsStringIO, sep=\",\", header=None))\n",
    "\n",
    "    csvRegexStringIO = StringIO(disallowedRegexList)\n",
    "    sortedRegexList = np.array(pd.read_csv(csvRegexStringIO, sep=\",\", header=None))\n",
    "\n",
    "    termIndexKey = {} \n",
    "    termWeightKey = {}\n",
    "    disallowedList = []\n",
    "    overallTermCount = {}\n",
    "    for item in sortedList:\n",
    "        termIndexKey.update({item[1]:item[0]})\n",
    "        termWeightKey.update({item[1]:item[2]})\n",
    "        disallowedList.append(item[1])\n",
    "    \n",
    "    regexIndexKey = {} \n",
    "    regexWeightKey = {}\n",
    "    disallowedRegexList = []\n",
    "    overallRegexCount = {}\n",
    "    for item in sortedRegexList:\n",
    "        termIndexKey.update({item[1]:item[0]})\n",
    "        termWeightKey.update({item[1]:item[2]})\n",
    "        disallowedRegexList.append(item[1])\n",
    "\n",
    "    '''The loaded notebooks are then placed into a list called \"uncheckedNotebooks\", which is the tool's way of iterating\n",
    "    through which notebooks need checking and which notebooks have already been checked.'''\n",
    "\n",
    "    checkedNotebooks = {}\n",
    "    print(\"Notebooks Successfully Loaded: \\n\" + str(notebookList))\n",
    "    sortedNotebookList = StringIO(notebookList)\n",
    "    uncheckedNotebooks = np.array(pd.read_csv(sortedNotebookList, sep=\",\", header=None))\n",
    "    print(\"\\nNumber of Jupyter Notebooks to be analysed: \" + str(len(uncheckedNotebooks)))\n",
    "\n",
    "    '''Below we loop through the unchecked notebooks and read the contents using the function \"readNotebook\"'''\n",
    "\n",
    "    for uncheckedNotebook in uncheckedNotebooks:\n",
    "        print(f\"\\nNotebook Name: \"  + os.path.basename(uncheckedNotebook[0]))\n",
    "        overallScore = 0\n",
    "        notebook = {}\n",
    "        # here we check line by line the the terms found which are added to a list \n",
    "        notebookToRead = str(f\"{path.join(directory, uncheckedNotebook[0])}\")\n",
    "        contents = readNotebook(notebookToRead)\n",
    "        \n",
    "        lineNum = 1\n",
    "\n",
    "        '''Initialising the term and regex count to zero at the start of every unchecked notebook so the number of terms\n",
    "        and regex resets for every new unchecked notebook.'''\n",
    "\n",
    "        for item in sortedList:\n",
    "            overallTermCount[item[1]] = 0\n",
    "        \n",
    "        for item in sortedRegexList:\n",
    "            overallRegexCount[item[1]] = 0\n",
    "        \n",
    "        overallTermCountByLine = {}\n",
    "        overallPatternCountByLine = {}\n",
    "        \n",
    "        '''Initialising the contentLineNum at zero at the start of every notebook and increasing with every contentLine\n",
    "        so an accurate line number can be shown. This will be important later so line-by-line analysis can be displayed.'''\n",
    "        \n",
    "        contentLineNum = 0\n",
    "        for contentLine in contents:\n",
    "            contentLineNum += 1\n",
    "            termResults = checkTerms(contentLine, disallowedList)\n",
    "            if termResults != False:\n",
    "                # print(termResults)\n",
    "                overallTermCountByLine[lineNum] = termResults\n",
    "                for term in overallTermCount:\n",
    "                    if termResults[term] > 0 :\n",
    "                        overallTermCount[term] += termResults[term]\n",
    "                        overallScore += termResults[term]\n",
    "                        print(f\"\\n Line: {contentLineNum}  - Error Type: Denied Keyword ({term}) \\n Line Contents:  {contentLine}\")\n",
    "            else:\n",
    "                overallTermCountByLine[lineNum] = 'none found'\n",
    "            \n",
    "            regExOutput = checkRegex(disallowedRegexList, contentLine)\n",
    "            if regExOutput != False:\n",
    "                overallPatternCountByLine[lineNum] = regExOutput\n",
    "                for patternsFound in overallRegexCount:\n",
    "                    if regExOutput[patternsFound] > 0 :\n",
    "                        overallRegexCount[patternsFound] += regExOutput[patternsFound]\n",
    "                        overallScore += regExOutput[patternsFound]\n",
    "                        print(f\"\\n Line: {contentLineNum}  - Error Type: RegEx ({patternsFound}) \\n Line Contents:  {contentLine}\")\n",
    "                \n",
    "            lineNum += 1\n",
    "        print(f\"\\nDeny-List Terms Found: \" + str(overallTermCount))\n",
    "        print(f\"RegEx Found: \" + str(overallRegexCount))\n",
    "        print(\"Notebook Overall Score: \" + str(overallScore))\n",
    "        checkedNotebooks.update({str(uncheckedNotebook): {'overallScore': overallScore,'overallTermCount' : str(overallTermCount),'overallTermCountByLine' : str(overallTermCountByLine), 'overallPatternCount' : str(overallRegexCount),'overallPatternCountByLine' : str(overallPatternCountByLine)}})\n",
    "  \n",
    "        \n",
    "    return checkedNotebooks \n",
    "        \n",
    "notebookResults = notebookChecker(disallowedTermsList, disallowedRegexList, notebookList)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Here we check results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "totals = {}\n",
    "# print(notebookResults.keys())\n",
    "for result in notebookResults:  \n",
    "    totals[result] = notebookResults[result].get('overallScore')\n",
    "    # return back to dictionary for graphs\n",
    "# print(totals)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visual Description\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "orderedResults = { nb:score for nb,score in sorted(totals.items(), key=lambda item:item[1])}\n",
    "df = pd.DataFrame.from_dict(orderedResults, orient='index', columns=[('Total Score')])\n",
    "print(df)\n",
    "#PLot examples\n",
    "f = plt.figure()\n",
    "f.set_figwidth(3)\n",
    "f.set_figheight(5)\n",
    "plt.bar(range(len(orderedResults)),list(orderedResults.values()),align='center',color=['r','g','b'])\n",
    "plt.xticks(range(len(orderedResults)),list(orderedResults.keys()))\n",
    "plt.xlabel('Notebook Names')\n",
    "plt.ylabel('Score')\n",
    "plt.show\n",
    "\n",
    "print('Regex patterns Found by notebook')\n",
    "for result in notebookResults:\n",
    "    terms = ast.literal_eval(notebookResults[result]['overallPatternCount'])\n",
    "    terms = pd.DataFrame.from_dict(terms, orient='index', columns=[(result)])\n",
    "    print(terms)\n",
    "\n",
    "print('Terms Found by notebook')\n",
    "for result in notebookResults:\n",
    "    terms = ast.literal_eval(notebookResults[result]['overallTermCount'])\n",
    "    g = plt.figure()\n",
    "    g.set_figwidth(3)\n",
    "    g.set_figheight(5)\n",
    "    plt.bar(range(len(terms)),list(terms.values()),align='center',color=['r','g','b'])\n",
    "    plt.xticks(range(len(terms)),list(terms.keys()))\n",
    "    plt.xlabel(f\" {result}\")\n",
    "    plt.ylabel('Score')\n",
    "    plt.show\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Detailed Report <a id=\"Detailed Report\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Save variables in the notebook checker function and then print them here.'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ad2bdc8ecc057115af97d19610ffacc2b4e99fae6737bb82f5d7fb13d2f2c186"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
